### Overview
This notebook demonstrates the implementation of gradient descent for multiple variable linear regression using vectorized operations in Python. It covers the following key steps:
- **Data Preparation:** Defines the training data (X_train and y_train) for a linear regression problem with multiple features.
- **Model Initialization:** Initializes the model parameters (weights w and bias b).
- **Prediction Functions:** Implements both element-wise and vectorized prediction functions.
- **Cost Function:** Computes the cost (mean squared error) for the linear regression model.
- **Gradient Calculation:** Calculates the gradients for the weights and bias using vectorized operations.
- **Gradient Descent:** Performs gradient descent to optimize the model parameters and minimize the cost function.
- **Visualization:** Plots the cost versus iteration to monitor the convergence of the algorithm.
